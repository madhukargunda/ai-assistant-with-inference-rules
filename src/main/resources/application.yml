spring:
  application:
    name: ai-assistant-with-inference-rules
  profiles:
    active:
      - handbook
  ai:
    model:
      chat: openai
    openai:
      api-key: ${OPENAI_API_KEY}
      chat:
        enabled: true
        options:
          temperature: 0
          top-p: 1
          model: gpt-4o
      embedding:
        options:
          model: text-embedding-ada-002
    ollama:
      base-url: http://localhost:11434
      init:
        pull-model-strategy: ALWAYS
      chat:
        enabled: false
        options:
          model: llama3.2:3b
          temperature: 0.7
      embedding:
        model: nomic-embed-text

logging:
  level:
    org.springframework.ai.chat.client.advisor : debug

